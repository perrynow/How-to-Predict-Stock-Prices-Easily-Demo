{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/perrynow/How-to-Predict-Stock-Prices-Easily-Demo/blob/master/Copy_of_%5BMake_a_copy%5D_VertexAI_Anon_Bob.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copyright 2025 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "metadata": {
        "id": "ikIep-HBcvvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qw6ttkOtrQ_D"
      },
      "source": [
        "# EAP: Anon Bob on Vertex AI"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Author |\n",
        "| --- |\n",
        "| [Katie Nguyen](https://github.com/katiemn) |"
      ],
      "metadata": {
        "id": "uDN8B4CBdMNs"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0e4d036833c"
      },
      "source": [
        "## Overview\n",
        "\n",
        "**CONFIDENTIAL, DO NOT CIRCULATE**\n",
        "\n",
        "<font color='red'> Per the Early Access Program terms, do not publicly share or publish information about this feature (including its outputs) until given permission by the Vertex AI team. Do not use the model in production or with external end users.</font>\n",
        "\n",
        "This notebook will show you how to use the upcoming image model (codenamed `anon-bob`). This new model is able to show its work, allowing you to see the 'thought process' behind the generated output.\n",
        "\n",
        "In this tutorial, you'll learn how to use the model in Vertex AI using the Google Gen AI SDK to try out the following scenarios:\n",
        "\n",
        "- Image generation:\n",
        "  - Text-to-image generation\n",
        "  - Model thoughts\n",
        "  - Grounding with search\n",
        "- Image editing:\n",
        "  - Localization\n",
        "  - Multi-turn image editing (chat)\n",
        "  - Editing with multiple reference images\n",
        "\n",
        "**NOTE:** Expect higher latency when using this model compared to Gemini 2.5 Flash Image (Nano Banana) as a result of the more advanced capabilities.\n",
        "\n",
        "**DISCLAIMER: Features are subject to change at any time. This model is experimental, so it may be unstable. There is very limited capacity for testing, so please limit to <font color='red'>10QPM</font>.**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# We want your feedback!\n",
        "\n",
        "Your experience and insights are important to us as we refine Image-out for general availability. We'd particularly love to hear about:\n",
        "\n",
        "* What use cases do you have in mind for Anon-Bob? Please provide a quote and example image for how you are using Anon-Bob and where it was helpful.\n",
        "* How does the new text rendering capability impact your workflows?\n",
        "* Are you finding the new Google Search integration useful for creating grounded imagery?\n",
        "* What are your thoughts on the latency versus quality trade-off for this larger model?\n",
        "\n",
        "\n",
        "Give us your feedback on this [form](https://forms.gle/HFVNzat1NaMZLPaL8). Also tell us if you are interested in **being featured in our launch communications**."
      ],
      "metadata": {
        "id": "Aac3KP3dktmf"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mfk6YY3G5kqp"
      },
      "source": [
        "## Get started"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install Google Gen AI SDK for Python\n",
        "\n",
        "For confidentiality reasons, the SDK is in a private GCP bucket."
      ],
      "metadata": {
        "id": "uJqUEH_mg6kb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-VBT2jIXLD7h"
      },
      "outputs": [],
      "source": [
        "%pip install --upgrade --quiet google-genai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Authenticate your notebook environment (Colab only)\n",
        "\n",
        "If you are running this notebook on Google Colab, run the following cell to authenticate your environment."
      ],
      "metadata": {
        "id": "eLIrxLFihSoE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ],
      "metadata": {
        "id": "hP-_lnBZhUjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import libraries"
      ],
      "metadata": {
        "id": "oukaeL9Thgy4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, Markdown, display\n",
        "from google import genai\n",
        "from google.genai import types"
      ],
      "metadata": {
        "id": "227VoQtmhjRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set Google Cloud project information and create client\n",
        "\n",
        "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n",
        "\n",
        "Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
      ],
      "metadata": {
        "id": "VdO2n52RhwBG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "PROJECT_ID = \"\"  # @param {type: \"string\", placeholder: \"[your-project-id]\", isTemplate: true}\n",
        "if not PROJECT_ID or PROJECT_ID == \"[your-project-id]\":\n",
        "    PROJECT_ID = str(os.environ.get(\"GOOGLE_CLOUD_PROJECT\"))\n",
        "\n",
        "LOCATION = \"global\"\n",
        "\n",
        "client = genai.Client(vertexai=True, project=PROJECT_ID, location=LOCATION)"
      ],
      "metadata": {
        "id": "lpI4Mo0phyq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOov6dpG99rY"
      },
      "source": [
        "### Load the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "27Fikag0xSaB"
      },
      "outputs": [],
      "source": [
        "MODEL_ID = \"anon-bob\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image generation"
      ],
      "metadata": {
        "id": "xuHBu3aRiYYv"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2i8O36nTHI1"
      },
      "source": [
        "### Text-to-image\n",
        "\n",
        "In the cell below, you'll call the `generate_content` method and modify the following arguments:\n",
        "\n",
        "  - `prompt`: A text only user message describing the image to be generated.\n",
        "  - `config`: A config for specifying content settings.\n",
        "    - `response_modalities`: To generate an image, you must include `IMAGE` in the `response_modalities` list. To get both text and images, specify `IMAGE` and `TEXT`.\n",
        "    - `ImageConfig`: Set the `aspect_ratio`. Valid ratios are: 1:1, 3:2, 2:3, 3:4, 4:3, 4:5, 5:4, 9:16, 16:9, 21:9\n",
        "\n",
        "All generated images include a [SynthID watermark](https://deepmind.google/technologies/synthid/), which can be verified via the Media Studio in [Vertex AI Studio](https://cloud.google.com/generative-ai-studio?hl=en)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NZsZMcA-iPSj"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"\n",
        "Generate a hyper-realistic infographic of a gourmet cheeseburger, deconstructed to show the texture of the toasted brioche bun, the seared crust of the patty, and the glistening melt of the cheese.\n",
        "\"\"\"\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=prompt,\n",
        "    config=types.GenerateContentConfig(\n",
        "        response_modalities=['IMAGE', 'TEXT'],\n",
        "        image_config=types.ImageConfig(\n",
        "            aspect_ratio=\"16:9\",\n",
        "        ),\n",
        "    ),\n",
        ")\n",
        "\n",
        "# Check for errors if an image is not generated\n",
        "if response.candidates[0].finish_reason != types.FinishReason.STOP:\n",
        "    reason = response.candidates[0].finish_reason\n",
        "    raise ValueError(f\"Prompt Content Error: {reason}\")\n",
        "\n",
        "for part in response.candidates[0].content.parts:\n",
        "    if part.thought:\n",
        "        continue # skip displaying thoughts\n",
        "    if part.inline_data:\n",
        "        display(Image(data=part.inline_data.data, width=1000))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### See the thoughts\n",
        "\n",
        "This is a thinking model, you can check the thoughts that led to the image being produced."
      ],
      "metadata": {
        "id": "mbpegA7YhkxI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for part in response.parts:\n",
        "  if part.thought:\n",
        "    if part.text:\n",
        "      display(Markdown(part.text))\n",
        "    elif part.inline_data:\n",
        "      display(Image(data=part.inline_data.data, width=500))"
      ],
      "metadata": {
        "id": "KzKLlFCYhzov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Use search grounding\n",
        "\n",
        "Note that the model is only grounded on text results and not images that can be found on Google Search."
      ],
      "metadata": {
        "id": "Ys_8nuIENJP9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "Visualize the current weather forecast for the next 5 days in San Francisco in a clean, modern weather chart. Add a visual on what I could wear each day.\n",
        "\"\"\"\n",
        "google_search = types.Tool(google_search=types.GoogleSearch())\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=prompt,\n",
        "    config=types.GenerateContentConfig(\n",
        "        response_modalities=['TEXT', 'IMAGE'],\n",
        "        image_config=types.ImageConfig(\n",
        "            aspect_ratio=\"21:9\",\n",
        "        ),\n",
        "        tools=[google_search],\n",
        "    )\n",
        ")\n",
        "\n",
        "for part in response.candidates[0].content.parts:\n",
        "    if part.text:\n",
        "        display(Markdown(part.text))\n",
        "    if part.inline_data:\n",
        "        display(Image(data=part.inline_data.data, width=500))"
      ],
      "metadata": {
        "id": "yWHgXTHldU_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nlhVQCuT6DS"
      },
      "source": [
        "## Image editing\n",
        "\n",
        "You can also edit images with this model, simply pass the original image as part of the prompt."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Localization\n",
        "\n",
        "You can also translate the text in images through image editing. Start by downloading the image and displaying it below."
      ],
      "metadata": {
        "id": "Y9FuL02EdvuN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://storage.googleapis.com/cloud-samples-data/generative-ai/image/flying-sneakers.png\n",
        "\n",
        "starting_image = \"flying-sneakers.png\"\n",
        "display(Image(filename=starting_image, width=500))"
      ],
      "metadata": {
        "id": "Jp0X8wEjhjLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HjIBLjr-il1y"
      },
      "outputs": [],
      "source": [
        "with open(starting_image, \"rb\") as f:\n",
        "    image = f.read()\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[\n",
        "        types.Part.from_bytes(\n",
        "            data=image,\n",
        "            mime_type=\"image/png\",\n",
        "        ),\n",
        "        \"Change the text in this infographic from English to Spanish.\",\n",
        "    ],\n",
        "    config=types.GenerateContentConfig(\n",
        "        response_modalities=['TEXT', 'IMAGE'],\n",
        "        image_config=types.ImageConfig(\n",
        "            image_size=\"1K\",\n",
        "        ),\n",
        "    )\n",
        ")\n",
        "\n",
        "for part in response.candidates[0].content.parts:\n",
        "    if part.text:\n",
        "        display(Markdown(part.text))\n",
        "    if part.inline_data:\n",
        "        display(Image(data=part.inline_data.data, width=500))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sIquv-1lAzn"
      },
      "source": [
        "### Multi-turn image editing (chat)\n",
        "\n",
        "In this next section, you'll generate a starting image and iteratively alter certain aspects of the image by chatting with the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05m25YRrB9Wg"
      },
      "outputs": [],
      "source": [
        "chat = client.chats.create(\n",
        "    model=MODEL_ID,\n",
        "    config=types.GenerateContentConfig(\n",
        "        response_modalities=['TEXT', 'IMAGE']\n",
        "    )\n",
        ")\n",
        "\n",
        "message = \"Create an image of a clear perfume bottle sitting on a vanity.\"\n",
        "response = chat.send_message(message)\n",
        "\n",
        "for part in response.candidates[0].content.parts:\n",
        "    if part.text:\n",
        "        display(Markdown(part.text))\n",
        "    if part.inline_data:\n",
        "        display(Image(data=part.inline_data.data, width=500))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bMp_cFHplh-Z"
      },
      "outputs": [],
      "source": [
        "message = \"Make the perfume bottle purple and add a vase of hydrangeas next to the bottle.\"\n",
        "response = chat.send_message(message)\n",
        "\n",
        "for part in response.candidates[0].content.parts:\n",
        "    if part.text:\n",
        "        display(Markdown(part.text))\n",
        "    if part.inline_data:\n",
        "        display(Image(data=part.inline_data.data, width=500))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQ_uiJOY5Sy9"
      },
      "source": [
        "### Multiple reference images\n",
        "\n",
        "While Gemini 2.5 Flash Image is limited to 3 reference images, this model supports up to 6.\n",
        "\n",
        "Run the following cell to visualize the starting images stored in Cloud Storage."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from PIL import Image as PIL_Image\n",
        "from io import BytesIO\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "image_urls = [\n",
        "    \"https://storage.googleapis.com/cloud-samples-data/generative-ai/image/woman.jpg\",\n",
        "    \"https://storage.googleapis.com/cloud-samples-data/generative-ai/image/suitcase.png\",\n",
        "    \"https://storage.googleapis.com/cloud-samples-data/generative-ai/image/armchair.png\",\n",
        "    \"https://storage.googleapis.com/cloud-samples-data/generative-ai/image/man-in-field.png\",\n",
        "    \"https://storage.googleapis.com/cloud-samples-data/generative-ai/image/shoes.jpg\",\n",
        "    \"https://storage.googleapis.com/cloud-samples-data/generative-ai/image/living-room.png\",\n",
        "]\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
        "for i, ax in enumerate(axes.flatten()):\n",
        "    ax.imshow(PIL_Image.open(BytesIO(requests.get(image_urls[i]).content)))\n",
        "    ax.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cUsResOwmBuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The process for sending the request is similar to previous image editing calls. The main difference is that you will provide multiple `Part.from_uri` instances, one for each reference image."
      ],
      "metadata": {
        "id": "ErSjXfZ2qg7F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[\n",
        "        types.Part.from_uri(\n",
        "            file_uri=\"gs://cloud-samples-data/generative-ai/image/woman.jpg\",\n",
        "            mime_type=\"image/jpeg\",\n",
        "        ),\n",
        "        types.Part.from_uri(\n",
        "            file_uri=\"gs://cloud-samples-data/generative-ai/image/suitcase.png\",\n",
        "            mime_type=\"image/png\",\n",
        "        ),\n",
        "        types.Part.from_uri(\n",
        "            file_uri=\"gs://cloud-samples-data/generative-ai/image/armchair.png\",\n",
        "            mime_type=\"image/png\",\n",
        "        ),\n",
        "        types.Part.from_uri(\n",
        "            file_uri=\"gs://cloud-samples-data/generative-ai/image/man-in-field.png\",\n",
        "            mime_type=\"image/png\",\n",
        "        ),\n",
        "        types.Part.from_uri(\n",
        "            file_uri=\"gs://cloud-samples-data/generative-ai/image/shoes.jpg\",\n",
        "            mime_type=\"image/jpeg\",\n",
        "        ),\n",
        "        types.Part.from_uri(\n",
        "            file_uri=\"gs://cloud-samples-data/generative-ai/image/living-room.png\",\n",
        "            mime_type=\"image/png\",\n",
        "        ),\n",
        "        \"Generate an image of a woman sitting in a living room with a man, both wearing sneakers. The woman is sitting in a white armchair with a blue suitcase next to her.\",\n",
        "    ],\n",
        "    config=types.GenerateContentConfig(\n",
        "        response_modalities=[\"TEXT\", \"IMAGE\"],\n",
        "        image_config=types.ImageConfig(\n",
        "            aspect_ratio=\"16:9\",\n",
        "        ),\n",
        "    ),\n",
        ")\n",
        "\n",
        "\n",
        "for part in response.candidates[0].content.parts:\n",
        "    if part.text:\n",
        "        display(Markdown(part.text))\n",
        "    if part.inline_data:\n",
        "        display(Image(data=part.inline_data.data, width=500))"
      ],
      "metadata": {
        "id": "_93g7aAeoyNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# We want your feedback!\n",
        "\n",
        "Your experience and insights are important to us as we refine Image-out for general availability. We'd particularly love to hear about:\n",
        "\n",
        "* What use cases do you have in mind for Anon-Bob? Please provide a quote and example image for how you are using Anon-Bob and where it was helpful.\n",
        "* How does the new text rendering capability impact your workflows?\n",
        "* Are you finding the new Google Search integration useful for creating grounded imagery?\n",
        "* What are your thoughts on the latency versus quality trade-off for this larger model?\n",
        "\n",
        "\n",
        "Give us your feedback on this [form](https://forms.gle/HFVNzat1NaMZLPaL8). Also tell us if you are interested in **being featured in our launch communications**."
      ],
      "metadata": {
        "id": "hMocIKCQIxSM"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}